# FeastFlow - End-to-End ML Pipeline with Feast Feature Store

ğŸš€ **Project Overview**  
FeastFlow is a comprehensive demonstration of a modern MLOps pipeline built around [Feast](https://feast.dev/), the open-source feature store. This project showcases a production-ready machine learning system designed to address real-world challenges such as training-serving skew, feature redundancy, and operational complexity.

**Primary Focus**: Demonstrate the power of Feast as the central feature management platform in an end-to-end ML workflow.

ğŸ¯ **Key Features**

- ğŸ“Š **Complete ETL Pipeline**: From raw data ingestion to engineered features.
- ğŸª **Feast Integration**: Offline and online feature stores powered by Redis.
- ğŸ¤– **ML Training & Inference**: Point-in-time correct training and real-time predictions.
- ğŸ¯ **Streamlit Dashboard**: Interactive UI to explore the entire pipeline.
- ğŸ”— **Version Control**: Git and DVC for complete reproducibility.
- ğŸ³ **Containerization**: Docker support for seamless deployment.

ğŸ—ï¸ **Architecture**  
![Architecture Diagram](https://raw.githubusercontent.com/dangnha/FeastFlow/master/static/pipeline.png) _(Placeholder for architecture diagram)_

ğŸ“ **Project Structure**

```
feastflow-demo/
â”œâ”€â”€ data/                    # Datasets
â”‚   â”œâ”€â”€ raw/                # Raw dataset from Kaggle
â”‚   â””â”€â”€ processed/          # Transformed and cleaned data
â”œâ”€â”€ feature_repo/            # Feast feature store
â”‚   â”œâ”€â”€ feature_store.yaml  # Feast configuration
â”‚   â”œâ”€â”€ features.py         # Feature definitions
â”‚   â””â”€â”€ data/               # Feast registry
â”œâ”€â”€ scripts/                 # Pipeline scripts
â”‚   â”œâ”€â”€ download_data.py    # Data extraction from Kaggle
â”‚   â”œâ”€â”€ transform_data.py   # Feature engineering
â”‚   â”œâ”€â”€ setup_feast.py      # Feast initialization
â”‚   â””â”€â”€ train_model.py      # Model training
â”œâ”€â”€ api/                     # Inference service
â”‚   â””â”€â”€ app.py              # FastAPI service
â”œâ”€â”€ model/                   # Trained models and metadata
â”œâ”€â”€ streamlit_app.py         # Interactive dashboard
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ docker-compose.yml       # Multi-service setup
â””â”€â”€ run.sh                  # One-click demo script
```

ğŸ› ï¸ **Technologies Used**

- **Feature Store**: Feast 0.31.0
- **Backend**: FastAPI, Uvicorn
- **Frontend**: Streamlit
- **Database**: Redis (online store), Parquet files (offline store)
- **ML Framework**: Scikit-learn, XGBoost
- **Data Processing**: Pandas, NumPy
- **Version Control**: Git, DVC
- **Containerization**: Docker, Docker Compose
- **Visualization**: Plotly

ğŸ“‹ **Prerequisites**

- Python 3.8+
- Docker and Docker Compose
- Git
- Kaggle API credentials for downloading data

ğŸš€ **Quick Start**

```bash
# Clone the repository
git clone https://github.com/dangnha/FeastFlow.git>
cd feastflow-demo

# Install dependencies
pip install -r requirements.txt

# Run the complete demo
bash run.sh
```

**Note**:

- Ensure Docker is running (e.g., open Docker Desktop on Windows).
- Set up Kaggle API credentials in your environment (see [Kaggle API documentation](https://www.kaggle.com/docs/api)).

ğŸ“Š **Dataset**  
This project uses the [Telco Customer Churn dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) from Kaggle, which includes:

- 7,043 customers with 21 features
- A mix of numerical and categorical data
- A clear business problem: churn prediction
- Temporal elements ideal for Feast demonstrations

ğŸ® **Using the Demo**

**Streamlit Dashboard**  
Access the interactive dashboard at: [http://localhost:8501](http://localhost:8501)

Features:

- ğŸ” Select any customer from the dataset.
- ğŸ¤– Get real-time churn predictions.
- ğŸª View features served from the Feast online store.
- ğŸ“Š Explore pipeline visualizations and metrics.
- ğŸ¯ Understand feature importance.

**API Endpoints**

- **Health Check**: `GET http://localhost:8000/health`
- **Prediction**:
  ```bash
  POST http://localhost:8000/predict
  {
      "customer_id": "1234-ABCD"
  }
  ```
- **Feature Retrieval**: `GET http://localhost:8000/features/1234-ABCD`
- **API Documentation**: [http://localhost:8000/docs](http://localhost:8000/docs)

ğŸª **Feast Implementation**  
**Feature Views**:

- **Customer Demographics**: Static customer information.
- **Customer Financials**: Monthly charges, tenure, and totals.
- **Customer Contract**: Service and contract details.

**Key Feast Concepts Demonstrated**:

- **Entities**: Customer as the primary entity.
- **Feature Views**: Logical grouping of features.
- **Offline Store**: Historical features for training.
- **Online Store**: Low-latency feature serving.
- **Point-in-Time Correctness**: Prevents data leakage.
- **Feature Materialization**: Keeps the online store updated.

ğŸ”§ **Development**  
**Adding New Features**:

1. Update `feature_repo/features.py`.
2. Apply changes: `feast apply`.
3. Materialize to the online store: `feast materialize`.

**Model Retraining**:

```bash
python scripts/train_model.py
```

Built with â¤ï¸ for the AIO2025 community.
